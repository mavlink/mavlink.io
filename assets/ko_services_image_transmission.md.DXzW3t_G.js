import{_ as a,c as t,a8 as i,o}from"./chunks/framework.CnRC9NRC.js";const g=JSON.parse('{"title":"Image Transmission Protocol","description":"","frontmatter":{},"headers":[],"relativePath":"ko/services/image_transmission.md","filePath":"ko/services/image_transmission.md"}'),s={name:"ko/services/image_transmission.md"};function l(n,e,c,r,m,d){return o(),t("div",null,e[0]||(e[0]=[i(`<h1 id="image-transmission-protocol" tabindex="-1">Image Transmission Protocol <a class="header-anchor" href="#image-transmission-protocol" aria-label="Permalink to &quot;Image Transmission Protocol&quot;">​</a></h1><div class="warning custom-block github-alert"><p class="custom-block-title">WARNING</p><p>The <a href="./../services/camera.html">Camera Protocol</a> and <a href="./../services/ftp.html">MAVLink FTP</a> are recommended for sending images, video and files.</p><p>This protocol is not intended for general image transmission use (it was originally designed as a simple protocol for transfering small images over a low bandwidth channel from an optical flow sensor to a GCS).</p></div><p>The image transmission protocol uses MAVLink as the communication channel to transport any kind of image (raw images, Kinect data, etc.) from one MAVLink node to another. It basically takes a live camera image, splits it into small chunks and sends it over MAVLink.</p><p>This topic describes how the image streaming functionality works and covers both the communication protocol and implementation details (for a vehicle and <em>QGroundControl</em>).</p><h2 id="communication" tabindex="-1">Communication <a class="header-anchor" href="#communication" aria-label="Permalink to &quot;Communication&quot;">​</a></h2><p>The image streaming component uses two MAVLink messages: a handshake message, <a href="./../messages/common.html#DATA_TRANSMISSION_HANDSHAKE">DATA_TRANSMISSION_HANDSHAKE</a>, to initiate image streaming and describe the image to be sent, and a data container message, <a href="./../messages/common.html#ENCAPSULATED_DATA">ENCAPSULATED_DATA</a>, to transport the image data.</p><p><a href="https://mermaid-js.github.io/mermaid-live-editor/#/edit/eyJjb2RlIjoic2VxdWVuY2VEaWFncmFtO1xuICAgIHBhcnRpY2lwYW50IEdDU1xuICAgIHBhcnRpY2lwYW50IERyb25lXG4gICAgR0NTLT4-RHJvbmU6IFJlcXVlc3QgaW1hZ2UgKERBVEFfVFJBTlNNSVNTSU9OX0hBTkRTSEFLRSlcbiAgICBEcm9uZS0-PkRyb25lOiBXYWl0IGZvciBpbWFnZSBmcm9tIGNhbWVyYS4gXG4gICAgRHJvbmUtPj5Ecm9uZTogRW5jb2RlIGltYWdlIChKUEVHKS5cbiAgICBEcm9uZS0-PkdDUzogU2VuZCBpbWFnZSBtZXRhZGF0YSAoREFUQV9UUkFOU01JU1NJT05fSEFORFNIQUtFKVxuICAgIERyb25lLT4-RHJvbmU6IFNwbGl0IGltYWdlIGludG8gY2h1bmtzLlxuICAgIERyb25lLT4-R0NTOiBTZW5kIGltYWdlIGNodW5rcyAoRU5DQVBTVUxBVEVEX0RBVEEpXG4gICAgR0NTLT4-R0NTOiBSZWNlaXZlIGltYWdlIGNodW5rcy5cbiAgICBHQ1MtPj5HQ1M6IFJlLWFzc2VtYmxlIGltYWdlIGFuZCBkaXNwbGF5LlxuICAgIE5vdGUgb3ZlciBHQ1MsRHJvbmU6IE1BViB1c2VzIERBVEFfVFJBTlNNSVNTSU9OX0hBTkRTSEFLRSB0byBpbmRpY2F0ZSBzdGFydCBvZiBuZXcgaW1hZ2VcblxuXG4gICAgR0NTLT4-RHJvbmU6IFJlcXVlc3QgdG8gc3RvcCBpbWFnZSBzdHJlYW0gKERBVEFfVFJBTlNNSVNTSU9OX0hBTkRTSEFLRSlcbiAgICBEcm9uZS0-PkRyb25lOiBTdG9wIGltYWdlIHByZXBhcmF0aW9uXG4gICAgRHJvbmUtPj5HQ1M6IEFja25vd2xlZGdlIHRvIHN0b3AgaW1hZ2Ugc3RyZWFtICg_KSIsIm1lcm1haWQiOnsidGhlbWUiOiJkZWZhdWx0In0sInVwZGF0ZUVkaXRvciI6ZmFsc2V9" target="_blank" rel="noreferrer"><img src="https://mermaid.ink/img/eyJjb2RlIjoic2VxdWVuY2VEaWFncmFtO1xuICAgIHBhcnRpY2lwYW50IEdDU1xuICAgIHBhcnRpY2lwYW50IERyb25lXG4gICAgR0NTLT4-RHJvbmU6IFJlcXVlc3QgaW1hZ2UgKERBVEFfVFJBTlNNSVNTSU9OX0hBTkRTSEFLRSlcbiAgICBEcm9uZS0-PkRyb25lOiBXYWl0IGZvciBpbWFnZSBmcm9tIGNhbWVyYS4gXG4gICAgRHJvbmUtPj5Ecm9uZTogRW5jb2RlIGltYWdlIChKUEVHKS5cbiAgICBEcm9uZS0-PkdDUzogU2VuZCBpbWFnZSBtZXRhZGF0YSAoREFUQV9UUkFOU01JU1NJT05fSEFORFNIQUtFKVxuICAgIERyb25lLT4-RHJvbmU6IFNwbGl0IGltYWdlIGludG8gY2h1bmtzLlxuICAgIERyb25lLT4-R0NTOiBTZW5kIGltYWdlIGNodW5rcyAoRU5DQVBTVUxBVEVEX0RBVEEpXG4gICAgR0NTLT4-R0NTOiBSZWNlaXZlIGltYWdlIGNodW5rcy5cbiAgICBHQ1MtPj5HQ1M6IFJlLWFzc2VtYmxlIGltYWdlIGFuZCBkaXNwbGF5LlxuICAgIE5vdGUgb3ZlciBHQ1MsRHJvbmU6IE1BViB1c2VzIERBVEFfVFJBTlNNSVNTSU9OX0hBTkRTSEFLRSB0byBpbmRpY2F0ZSBzdGFydCBvZiBuZXcgaW1hZ2VcblxuXG4gICAgR0NTLT4-RHJvbmU6IFJlcXVlc3QgdG8gc3RvcCBpbWFnZSBzdHJlYW0gKERBVEFfVFJBTlNNSVNTSU9OX0hBTkRTSEFLRSlcbiAgICBEcm9uZS0-PkRyb25lOiBTdG9wIGltYWdlIHByZXBhcmF0aW9uXG4gICAgRHJvbmUtPj5HQ1M6IEFja25vd2xlZGdlIHRvIHN0b3AgaW1hZ2Ugc3RyZWFtICg_KSIsIm1lcm1haWQiOnsidGhlbWUiOiJkZWZhdWx0In0sInVwZGF0ZUVkaXRvciI6ZmFsc2V9" alt=""></a></p><ol><li><p>The communication is initiated by the <em>QGroundControl</em> with a <code>DATA_TRANSMISSION_HANDSHAKE</code> request to start the stream. The messages should specify:</p><ul><li><code>type</code>: any of the types in the enum <a href="./../messages/common.html#MAVLINK_DATA_STREAM_TYPE">MAVLINK_DATA_STREAM_TYPE</a> in <strong>mavlink.h</strong>,</li><li><code>jpg_quality</code>: Desired image quality (for lossy formats like JPEG).</li><li>All other fields must be zero in the initial request.</li></ul></li><li><p>When the targeted MAV receives the handshake request, it sends back a <code>DATA_TRANSMISSION_HANDSHAKE</code>. This acts provides acknowledgment of the request and information about the image that is about to be streamed:</p><ul><li><code>type</code>: Type of image to be streamed (same as requested type)</li><li><code>size</code>: Image size in bytes.</li><li><code>width</code>: Image width in pixels.</li><li><code>height</code>: Image height in pixels.</li><li><code>packets</code>: number of MAVLink <code>ENCAPSULATED_DATA</code> packets to be sent</li><li><code>payload</code>: Size of the payload of each data packet (normally 252 bytes)</li><li><code>jpg_quality</code>: Image quality (same as requested)</li></ul></li><li><p>The image data is then split into chunks to fit into <code>ENCAPSULATED_DATA</code> message and sent over MAVLink. Every packet contains a sequence number as well as the ID of the image stream it belongs to.</p></li><li><p>The image streamer periodically sends new images without further interaction. Every new image comes with a new <code>DATA_TRANSMISSION_HANDSHAKE</code> ACK packet with updated image <code>size</code>, <code>packets</code> and <code>payload</code> fields. After this ACK packet, the new image arrives as a series of <code>ENCAPSULATED_DATA</code> packets.</p><div class="note custom-block github-alert"><p class="custom-block-title">&gt; The sequence number starts at 0 for every new image of the stream.</p><p></p></div></li><li><p>To stop an image stream a GSC must send a new <code>DATA_TRANSMISSION_HANDSHAKE</code> request packet, with all 0 values. The MAVLink node will acknowledge this by sending back <code>DATA_TRANSMISSION_HANDSHAKE</code> also containing 0 values.</p></li></ol><h2 id="usage-configuration" tabindex="-1">Usage / Configuration <a class="header-anchor" href="#usage-configuration" aria-label="Permalink to &quot;Usage / Configuration&quot;">​</a></h2><p>To use the two modules on your MAV, you have to do the following steps:</p><ul><li>Compile the <code>mavconn</code> middleware for your MAV: <a href="https://www.pixhawk.org/wiki/software/mavconn/start" target="_blank" rel="noreferrer">Guide</a>, <a href="https://github.com/pixhawk/mavconn" target="_blank" rel="noreferrer">Github</a>.</li><li>Start at least these components on the MAV:<div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>px_mavlink_bridge_udp &amp;</span></span>
<span class="line"><span>px_system_control --heartbeat &amp;</span></span>
<span class="line"><span>px_camera -o lcm &amp;</span></span></code></pre></div></li><li>Compile and start <em>QGroundControl</em>.</li><li>Start the image streaming component (you can add the <code>-v</code> flag to see some more output): <code>px_imagestreamer</code>.</li><li>Initiate the image stream: Open the HUD widget, right-click into the widget and choose <strong>Enable live Image Streaming</strong>.</li></ul><p>You should now be able to see the live video feed with one image per second (default, hardcoded at the moment).</p><h2 id="developer" tabindex="-1">Developer <a class="header-anchor" href="#developer" aria-label="Permalink to &quot;Developer&quot;">​</a></h2><p>Out-of-the-box, the image streaming component only implements JPEG streaming of the camera image. To implement your own image stream, you have to do the following:</p><ul><li>Write a MAVLink handler, which handles requests to start image streams of your type of choice.</li><li>Write a data handler, which takes your desired data (i.e. a stereo camera image), encodes it into the format of your choice (i.e. rawimage, JPEG, BMP) and splits/sends the data over MAVLink.</li><li>Extend the data/message handler in the UAS component of <em>QGroundControl</em> to correctly handle your data (i.e. unpacking of the chosen format).</li><li>Write or extend a widget to display your data according to your wishes.</li></ul>`,15)]))}const p=a(s,[["render",l]]);export{g as __pageData,p as default};
